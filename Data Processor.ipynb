{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a718de178461ff4f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# WorldCup Dataset Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "232f9846f8f792e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download All Files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf4f008c99f30325"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load file names from : https://ita.ee.lbl.gov/html/contrib/worldcup-readme.txt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b97ebbd2bab02c5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# File Names Array\n",
    "\n",
    "files = [\n",
    "    \"wc_day1_1.gz\", \"wc_day2_1.gz\", \"wc_day3_1.gz\", \"wc_day4_1.gz\", \n",
    "    \"wc_day5_1.gz\", \"wc_day6_1.gz\", \"wc_day7_1.gz\", \"wc_day8_1.gz\", \n",
    "    \"wc_day9_1.gz\", \"wc_day10_1.gz\", \"wc_day11_1.gz\", \"wc_day12_1.gz\", \n",
    "    \"wc_day13_1.gz\", \"wc_day14_1.gz\", \"wc_day15_1.gz\", \"wc_day16_1.gz\", \n",
    "    \"wc_day17_1.gz\", \"wc_day18_1.gz\", \"wc_day19_1.gz\", \"wc_day20_1.gz\", \n",
    "    \"wc_day21_1.gz\", \"wc_day22_1.gz\", \"wc_day23_1.gz\", \"wc_day24_1.gz\", \n",
    "    \"wc_day25_1.gz\", \"wc_day26_1.gz\", \"wc_day27_1.gz\", \"wc_day28_1.gz\", \n",
    "    \"wc_day29_1.gz\", \"wc_day30_1.gz\", \"wc_day31_1.gz\", \"wc_day32_1.gz\", \n",
    "    \"wc_day33_1.gz\", \"wc_day34_1.gz\", \"wc_day35_1.gz\", \"wc_day36_1.gz\", \n",
    "    \"wc_day37_1.gz\", \"wc_day38_1.gz\", \"wc_day38_2.gz\", \"wc_day39_1.gz\", \n",
    "    \"wc_day39_2.gz\", \"wc_day40_1.gz\", \"wc_day40_2.gz\", \"wc_day41_1.gz\", \n",
    "    \"wc_day41_2.gz\", \"wc_day42_1.gz\", \"wc_day43_1.gz\", \"wc_day44_1.gz\", \n",
    "    \"wc_day44_2.gz\", \"wc_day44_3.gz\", \"wc_day45_1.gz\", \"wc_day45_2.gz\", \n",
    "    \"wc_day45_3.gz\", \"wc_day46_1.gz\", \"wc_day46_2.gz\", \"wc_day46_3.gz\", \n",
    "    \"wc_day46_4.gz\", \"wc_day46_5.gz\", \"wc_day46_6.gz\", \"wc_day46_7.gz\", \n",
    "    \"wc_day46_8.gz\", \"wc_day47_1.gz\", \"wc_day47_2.gz\", \"wc_day47_3.gz\", \n",
    "    \"wc_day47_4.gz\", \"wc_day47_5.gz\", \"wc_day47_6.gz\", \"wc_day47_7.gz\", \n",
    "    \"wc_day47_8.gz\", \"wc_day48_1.gz\", \"wc_day48_2.gz\", \"wc_day48_3.gz\", \n",
    "    \"wc_day48_4.gz\", \"wc_day48_5.gz\", \"wc_day48_6.gz\", \"wc_day48_7.gz\", \n",
    "    \"wc_day49_1.gz\", \"wc_day49_2.gz\", \"wc_day49_3.gz\", \"wc_day49_4.gz\", \n",
    "    \"wc_day50_1.gz\", \"wc_day50_2.gz\", \"wc_day50_3.gz\", \"wc_day50_4.gz\", \n",
    "    \"wc_day51_1.gz\", \"wc_day51_2.gz\", \"wc_day51_3.gz\", \"wc_day51_4.gz\", \n",
    "    \"wc_day51_5.gz\", \"wc_day51_6.gz\", \"wc_day51_7.gz\", \"wc_day51_8.gz\", \n",
    "    \"wc_day51_9.gz\", \"wc_day52_1.gz\", \"wc_day52_2.gz\", \"wc_day52_3.gz\", \n",
    "    \"wc_day52_4.gz\", \"wc_day52_5.gz\", \"wc_day52_6.gz\", \"wc_day53_1.gz\", \n",
    "    \"wc_day53_2.gz\", \"wc_day53_3.gz\", \"wc_day53_4.gz\", \"wc_day53_5.gz\", \n",
    "    \"wc_day53_6.gz\", \"wc_day54_1.gz\", \"wc_day54_2.gz\", \"wc_day54_3.gz\", \n",
    "    \"wc_day54_4.gz\", \"wc_day54_5.gz\", \"wc_day54_6.gz\", \"wc_day55_1.gz\", \n",
    "    \"wc_day55_2.gz\", \"wc_day55_3.gz\", \"wc_day55_4.gz\", \"wc_day55_5.gz\", \n",
    "    \"wc_day56_1.gz\", \"wc_day56_2.gz\", \"wc_day56_3.gz\", \"wc_day57_1.gz\", \n",
    "    \"wc_day57_2.gz\", \"wc_day57_3.gz\", \"wc_day58_1.gz\", \"wc_day58_2.gz\", \n",
    "    \"wc_day58_3.gz\", \"wc_day58_4.gz\", \"wc_day58_5.gz\", \"wc_day58_6.gz\", \n",
    "    \"wc_day59_1.gz\", \"wc_day59_2.gz\", \"wc_day59_3.gz\", \"wc_day59_4.gz\", \n",
    "    \"wc_day59_5.gz\", \"wc_day59_6.gz\", \"wc_day59_7.gz\", \"wc_day60_1.gz\", \n",
    "    \"wc_day60_2.gz\", \"wc_day60_3.gz\", \"wc_day60_4.gz\", \"wc_day60_5.gz\", \n",
    "    \"wc_day60_6.gz\", \"wc_day60_7.gz\", \"wc_day61_1.gz\", \"wc_day61_2.gz\", \n",
    "    \"wc_day61_3.gz\", \"wc_day61_4.gz\", \"wc_day61_5.gz\", \"wc_day61_6.gz\", \n",
    "    \"wc_day61_7.gz\", \"wc_day61_8.gz\", \"wc_day62_1.gz\", \"wc_day62_2.gz\", \n",
    "    \"wc_day62_3.gz\", \"wc_day62_4.gz\", \"wc_day62_5.gz\", \"wc_day62_6.gz\", \n",
    "    \"wc_day62_7.gz\", \"wc_day62_8.gz\", \"wc_day62_9.gz\", \"wc_day62_10.gz\", \"wc_day63_1.gz\", \n",
    "    \"wc_day63_2.gz\", \"wc_day63_3.gz\", \"wc_day63_4.gz\", \"wc_day64_1.gz\", \n",
    "    \"wc_day64_2.gz\", \"wc_day64_3.gz\", \"wc_day65_1.gz\", \"wc_day65_2.gz\", \n",
    "    \"wc_day65_3.gz\", \"wc_day65_4.gz\", \"wc_day65_5.gz\", \"wc_day65_6.gz\", \n",
    "    \"wc_day65_7.gz\", \"wc_day65_8.gz\", \"wc_day65_9.gz\", \"wc_day66_1.gz\", \n",
    "    \"wc_day66_2.gz\", \"wc_day66_3.gz\", \"wc_day66_4.gz\", \"wc_day66_5.gz\", \n",
    "    \"wc_day66_6.gz\", \"wc_day66_7.gz\", \"wc_day66_8.gz\", \"wc_day66_9.gz\", \n",
    "    \"wc_day66_10.gz\", \"wc_day66_11.gz\", \"wc_day67_1.gz\", \"wc_day67_2.gz\", \"wc_day67_3.gz\", \n",
    "    \"wc_day67_4.gz\", \"wc_day67_5.gz\", \"wc_day68_1.gz\", \"wc_day68_2.gz\", \n",
    "    \"wc_day68_3.gz\", \"wc_day69_1.gz\", \"wc_day69_2.gz\", \"wc_day69_3.gz\", \n",
    "    \"wc_day69_4.gz\", \"wc_day69_5.gz\", \"wc_day69_6.gz\", \"wc_day69_7.gz\", \n",
    "    \"wc_day70_1.gz\", \"wc_day70_2.gz\", \"wc_day70_3.gz\", \"wc_day71_1.gz\", \n",
    "    \"wc_day71_2.gz\", \"wc_day72_1.gz\", \"wc_day72_2.gz\", \"wc_day72_3.gz\", \n",
    "    \"wc_day73_1.gz\", \"wc_day73_2.gz\", \"wc_day73_3.gz\", \"wc_day73_4.gz\", \n",
    "    \"wc_day73_5.gz\", \"wc_day73_6.gz\", \"wc_day74_1.gz\", \"wc_day74_2.gz\", \n",
    "    \"wc_day74_3.gz\", \"wc_day74_4.gz\", \"wc_day74_5.gz\", \"wc_day74_6.gz\", \n",
    "    \"wc_day75_1.gz\", \"wc_day75_2.gz\", \"wc_day75_3.gz\", \"wc_day76_1.gz\", \n",
    "    \"wc_day76_2.gz\", \"wc_day77_1.gz\", \"wc_day77_2.gz\", \"wc_day78_1.gz\", \n",
    "    \"wc_day78_2.gz\", \"wc_day79_1.gz\", \"wc_day79_2.gz\", \"wc_day79_3.gz\", \n",
    "    \"wc_day79_4.gz\", \"wc_day80_1.gz\", \"wc_day80_2.gz\", \"wc_day81_1.gz\", \n",
    "    \"wc_day82_1.gz\", \"wc_day83_1.gz\", \"wc_day84_1.gz\", \"wc_day85_1.gz\", \n",
    "    \"wc_day86_1.gz\", \"wc_day87_1.gz\", \"wc_day88_1.gz\", \"wc_day89_1.gz\", \n",
    "    \"wc_day90_1.gz\", \"wc_day91_1.gz\", \"wc_day92_1.gz\"]\n",
    "\n",
    "print(f'Total Files : {len(files)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0be8ade4d9adea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download script for SFTP\n",
    "\n",
    "Sample File URL : ftp://ita.ee.lbl.gov/traces/WorldCup/wc_day92_1.gz"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12d11b30c37e5612"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def downloadFromFTP(filename):\n",
    "\n",
    "    try:\n",
    "        # Connect to the FTP server\n",
    "        ftp = ftplib.FTP('ita.ee.lbl.gov')\n",
    "        ftp.login()\n",
    "        \n",
    "        # Navigate to the Directory\n",
    "        ftp.cwd('/traces/WorldCup/')\n",
    "        \n",
    "        # Download File\n",
    "        localpath = 'rawdata/wc/' + filename\n",
    "        with open(localpath, 'wb') as local_file:\n",
    "            ftp.retrbinary(f\"RETR {filename}\", local_file.write)\n",
    "        \n",
    "        print(f\"File Downloaded {filename} to {localpath}\")\n",
    "    \n",
    "    except ftplib.all_errors as e:\n",
    "        print(f\"FTP Error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        if 'ftp' in locals():\n",
    "            ftp.quit()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfb74df2133c2654"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download all files to 'rawdata/wc' folder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "281d9fbc118b9842"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    downloadFromFTP(file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2d0c2c58737b76c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process Downloaded RAW Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc9f07382b7e0b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parse the log line to extract timestamp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd80ca04be68e902"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245\n",
    "\n",
    "def parse_line(line):\n",
    "    parts = line.split()\n",
    "    timestamp_str = parts[3][1:]  # Remove the starting '['\n",
    "    timestamp = datetime.strptime(timestamp_str, '%d/%b/%Y:%H:%M:%S')\n",
    "    return timestamp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4a70509a154527a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate Commands For Log Recreation\n",
    "\n",
    "- Download toolset from ftp://ita.ee.lbl.gov/software/WorldCup_tools.tar.gz\n",
    "- Compile the log recreation tool by executing `make reduce`\n",
    "- Execute commands to convert to log format `gzip -dc rawdata/wc/wc_day90_1.gz | bin/recreate state/object_mappings.sort`\n",
    "\n",
    "\"recreate application\" need to be complied and stored inside `bin` folder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85ba436875b779a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute tool to convert log file and process\n",
    "\n",
    "- Convert bin file to txt file and save to temp folder\n",
    "- Read the log file and extract timestamps\n",
    "- Round the timestamp to last minute\n",
    "- Aggregate same values to provide timestamp | count dataset\n",
    "- Save to a temporary csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc947750a9427910"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    command = 'gzip -dc rawdata/wc/' + file + ' | bin/recreate bin/object_mappings.sort'\n",
    "    print(f\"Processing {command}\")\n",
    "    timestamps = []\n",
    "    \n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, encoding='utf-8', errors='replace')\n",
    "    \n",
    "    with open('temp/wc.txt', 'w', encoding='utf-8', errors='replace') as tempfile:\n",
    "        tempfile.write(result.stdout)\n",
    "        \n",
    "    with open('temp/wc.txt', 'r', encoding='utf-8', errors='replace') as datafile:\n",
    "        for line in datafile:\n",
    "            timestamp = parse_line(line)\n",
    "            timestamps.append(timestamp)\n",
    "            \n",
    "    if len(timestamps) > 0:\n",
    "        df = pd.DataFrame(timestamps, columns=['timestamp'])\n",
    "        df['minute'] = df['timestamp'].dt.floor('min')  # Round down to the nearest minute\n",
    "        df_aggregated = df.groupby('minute').size().reset_index(name='count')\n",
    "        df_aggregated.to_csv(f'temp/{file}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b60db7e395fb94c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Validate processed log files\n",
    "\n",
    "- Compare original log line count vs csv sum\n",
    "- Print if there are any mismatch files to recreate (Should manually check)\n",
    "\n",
    "Generate Commands For Log Validation\n",
    "\n",
    "- Download toolset from ftp://ita.ee.lbl.gov/software/WorldCup_tools.tar.gz\n",
    "- Compile the log recreation tool by executing `make read`\n",
    "- Execute commands to convert to log format `gzip -dc rawdata/wc/wc_day51_3.gz | bin/read`\n",
    "\n",
    "\"read application\" need to be complied and stored inside `bin` folder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2697ef7f84ff8bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extractLogLineCount(output):\n",
    "    lines = output.strip().split('\\n')\n",
    "    numeric_values = [int(line) for line in lines if line.isdigit()]\n",
    "    return numeric_values[-1] if numeric_values else 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3d48d5e0a9c700e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csvGrandTotal = 0\n",
    "logGrandTotal = 0\n",
    "mismatchFiles = []\n",
    "\n",
    "for file in files:\n",
    "    command = 'gzip -dc rawdata/wc/' + file + ' | bin/read'\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, encoding='utf-8', errors='replace')\n",
    "    logTotal = extractLogLineCount(result.stderr)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv('temp/' + file + '.csv')\n",
    "        csvTotal = df['count'].sum()\n",
    "    except:\n",
    "        csvTotal = 0\n",
    "    \n",
    "    print(f'Processed {file}, CSV: {csvTotal}, File:{logTotal}')\n",
    "    \n",
    "    csvGrandTotal += csvTotal\n",
    "    logGrandTotal += logTotal\n",
    "    \n",
    "    if csvTotal != logTotal:\n",
    "        mismatchFiles.append(file)\n",
    "    \n",
    "print(f'Total from CSV: {csvGrandTotal}')\n",
    "print(f'Total from Logs: {logGrandTotal}')\n",
    "print(f'Mismatch files: {mismatchFiles}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce38fc9f6cd2a8c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process temporary CSVs\n",
    "\n",
    "- Load all csv's from temp folder\n",
    "- Combine and create the final csv for model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ef48ab23a0bbc92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv_files = glob.glob('temp/wc_*.csv')\n",
    "print(f'Loaded {len(csv_files)} CSV files')\n",
    "\n",
    "aggregated_df = pd.DataFrame()\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    aggregated_df = pd.concat([aggregated_df, df])\n",
    "    \n",
    "# Group by 'minute' and sum the counts\n",
    "final_aggregated_df = aggregated_df.groupby('minute').sum().reset_index()\n",
    "\n",
    "# Save the final aggregated results to a CSV file\n",
    "final_aggregated_df.to_csv('processeddata/wc/requestdata.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f762010e6c21614"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NASA Dataset Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2300ccc3bf95381c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process downloaded files\n",
    "\n",
    "- Downloaded files (NASA_access_log_Jul95, NASA_access_log_Aug95) located at `rawdata/nasa`\n",
    "- Process 2 files to extract timestamps\n",
    "- Generate combined csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9a0c89bfd142476"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "\n",
    "with open('rawdata/nasa/NASA_access_log_Jul95', 'r', encoding='utf-8', errors='replace') as datafile:\n",
    "    for line in datafile:\n",
    "        try:\n",
    "            timestamp = parse_line(line)\n",
    "            timestamps.append(timestamp)\n",
    "        except:\n",
    "            print(f'Failed to decode : {line}')\n",
    "            \n",
    "with open('rawdata/nasa/NASA_access_log_Aug95', 'r', encoding='utf-8', errors='replace') as datafile:\n",
    "    for line in datafile:\n",
    "        timestamp = parse_line(line)\n",
    "        timestamps.append(timestamp)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d616e7c9047c3326"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(timestamps, columns=['timestamp'])\n",
    "df['minute'] = df['timestamp'].dt.floor('min')  # Round down to the nearest minute\n",
    "df_aggregated = df.groupby('minute').size().reset_index(name='count')\n",
    "df_aggregated.to_csv('processeddata/nasa/requestdata.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46f60da960e0e1b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36cfdc593102e6db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NASA Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf46d6c6399e64de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_nasa = pd.read_csv('processeddata/nasa/requestdata.csv')\n",
    "print (f'Total Requests : {df_nasa['count'].sum()}')\n",
    "\n",
    "df_nasa['minute'] = pd.to_datetime(df_nasa['minute'])\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(df_nasa['minute'], df_nasa['count'])\n",
    "plt.title('NASA - Count Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8085daf8761303b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### WC Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c2c3f36c59b60b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_wc = pd.read_csv('processeddata/wc/requestdata.csv')\n",
    "print (f'Total Requests : {df_wc['count'].sum()}')\n",
    "\n",
    "df_wc['minute'] = pd.to_datetime(df_wc['minute'])\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(df_wc['minute'], df_wc['count'])\n",
    "plt.title('WC - Count Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "246c270155512977"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
